{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import parsl\n",
    "import os\n",
    "from parsl.app.app import python_app, bash_app\n",
    "from parsl.configs.local_threads import config\n",
    "\n",
    "from parsl.providers import LocalProvider,CondorProvider\n",
    "from parsl.channels import LocalChannel,SSHChannel\n",
    "from parsl.config import Config\n",
    "from parsl.executors import HighThroughputExecutor\n",
    "\n",
    "from parsl.addresses import address_by_hostname\n",
    "\n",
    "x509_proxy = 'x509up_u%s'%(os.getuid())\n",
    "\n",
    "wrk_init = '''\n",
    "source /cvmfs/sft.cern.ch/lcg/views/LCG_95apython3/x86_64-centos7-gcc7-opt/setup.sh\n",
    "export PATH=`pwd`/.local/bin:$PATH\n",
    "export PYTHONPATH=`pwd`/.local/lib/python3.6/site-packages:$PYTHONPATH\n",
    "\n",
    "export X509_USER_PROXY=`pwd`/%s\n",
    "mkdir -p ./coffea_parsl_condor\n",
    "'''%(x509_proxy)\n",
    "\n",
    "twoGB = 2048\n",
    "nproc = 4\n",
    "\n",
    "condor_cfg = '''\n",
    "transfer_output_files = coffea_parsl_condor\n",
    "RequestMemory = %d\n",
    "RequestCpus = %d\n",
    "''' % (twoGB*nproc, nproc)\n",
    "\n",
    "xfer_files = ['%s/.local' % (os.environ['HOME'], ), '%s/%s' % (os.environ['HOME'], x509_proxy, )]\n",
    "\n",
    "#envs={'PYTHONPATH':'/afs/hep.wisc.edu/home/lgray/.local/lib/python3.6/site-packages:%s'%os.environ['PYTHONPATH'],\n",
    "#      'X509_USER_PROXY':'./%s'%x509_proxy,\n",
    "#      'PATH':'/afs/hep.wisc.edu/home/lgray/.local/bin:%s'%os.environ['PATH']}\n",
    "\n",
    "condor_htex = Config(\n",
    "    executors=[\n",
    "        HighThroughputExecutor(\n",
    "            label=\"coffea_parsl_condor\",\n",
    "            address=address_by_hostname(),\n",
    "            prefetch_capacity=0,\n",
    "            cores_per_worker=1,\n",
    "            max_workers=nproc,\n",
    "            worker_logdir_root='./',\n",
    "            provider=CondorProvider(\n",
    "                channel=LocalChannel(),\n",
    "                init_blocks=16,\n",
    "                max_blocks=200,\n",
    "                nodes_per_block=1,\n",
    "                worker_init = wrk_init,                \n",
    "                transfer_input_files=xfer_files,\n",
    "                scheduler_options=condor_cfg\n",
    "            ),\n",
    "        )\n",
    "    ],\n",
    "    strategy=None,\n",
    ")\n",
    "\n",
    "#parsl.set_stream_logger() # <-- log everything to stdout\n",
    "\n",
    "dfk = parsl.load(condor_htex)\n",
    "\n",
    "chunksize=500000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@python_app\n",
    "def hello ():\n",
    "    say_hello = 'Hello World!'\n",
    "    print(say_hello)\n",
    "    return say_hello\n",
    "\n",
    "print(hello().result())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "with open('metadata/samplefiles.json') as f:\n",
    "    temp = json.load(f)\n",
    "    datasets = temp['Hbb_2017']    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the hbb analysis worker from the cloudpickle file\n",
    "import cloudpickle as cpkl\n",
    "import lz4.frame as lz4f\n",
    "\n",
    "processor_pkl = 'boostedHbbProcessor.cpkl.lz4'\n",
    "processor_instance = None\n",
    "with lz4f.open(processor_pkl, mode=\"rb\") as fin:\n",
    "    processor_instance = cpkl.load(fin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from fnal_column_analysis_tools.processor import run_parsl_job\n",
    "from fnal_column_analysis_tools.processor.parsl.parsl_executor import parsl_executor\n",
    "\n",
    "tic = time.time()\n",
    "treenames = ['otree', 'Events']  # deal with mixed skims and full derived trees\n",
    "final_accumulator = run_parsl_job(datasets, treenames, processor_instance, parsl_executor, \n",
    "                                  executor_args={'config':None}, data_flow=dfk, chunksize=chunksize)\n",
    "dt = time.time() - tic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nevt = 1 # sum(parsl_executor.counts.values())\n",
    "print('processed:',nevt,'events')\n",
    "print('total time: ',dt/60)\n",
    "print('Î¼s/evt', dt/nevt*1e6)\n",
    "print('Mevt/s', nevt/dt/1e6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fnal_column_analysis_tools import hist\n",
    "import gzip\n",
    "import pickle\n",
    "import numexpr\n",
    "import numpy as np\n",
    "\n",
    "nbins = sum(sum(arr.size for arr in h._sumw.values()) for h in final_accumulator.values() if isinstance(h, hist.Hist))\n",
    "nfilled = sum(sum(np.sum(arr>0) for arr in h._sumw.values()) for h in final_accumulator.values() if isinstance(h, hist.Hist))\n",
    "print(\"Processed %.1fM events\" % (nevt/1e6, ))\n",
    "print(\"Filled %.1fM bins\" % (nbins/1e6, ))\n",
    "print(\"Nonzero bins: %.1f%%\" % (100*nfilled/nbins, ))\n",
    "\n",
    "# Pickle is not very fast or memory efficient, will be replaced by something better soon\n",
    "with lz4f.open(\"hists.cpkl.lz4\", mode=\"wb\", compression_level=6) as fout:\n",
    "    cpkl.dump(final_accumulator, fout)\n",
    "\n",
    "#dt = time.time() - tstart\n",
    "#print(\"%.2f us*cpu/event overall\" % (1e6*dt*nworkers/final_accumulators['nentries'], ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsl.dfk().cleanup()\n",
    "parsl.clear()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
